{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#  Self Study 3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this self study we perform character recognition using SVM classifiers. We use the MNIST dataset, which consists of 70000 handwritten digits 0..9 at a resolution of 28x28 pixels. \n",
    "\n",
    "Stuff we need:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import time\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import confusion_matrix,accuracy_score\n",
    "import sklearn\n",
    "#from sklearn.datasets import fetch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we get the MNIST data. Using the fetch_mldata function, this will be downloaded from the web, and stored in the directory you specify as data_home (replace my path in the following cell):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import fetch_openml\n",
    "mnist = fetch_openml(name='mnist_784', data_home='data')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The data has .data and .target attributes. The following gives us some basic information on the data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of datapoints: 70000\n",
      "\n",
      "Number of features: 784\n",
      "\n",
      "List of labels: ['0' '1' '2' '3' '4' '5' '6' '7' '8' '9']\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"Number of datapoints: {}\\n\".format(mnist.data.shape[0]))\n",
    "print(\"Number of features: {}\\n\".format(mnist.data.shape[1]))\n",
    "print(\"List of labels: {}\\n\".format(np.unique(mnist.target)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The mnist.data is represented as a Pandas dataframe (probably -- you may check this via type(mnist.data)). The following code expects mnist.data to be a plain np.array, which we get simply by running:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "mnist.data=np.array(mnist.data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can plot individual datapoints as follows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Value of datapoint no. 4:\n",
      "[  0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.\n",
      "   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.\n",
      "   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.\n",
      "   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.\n",
      "   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.\n",
      "   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.\n",
      "   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.\n",
      "   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.\n",
      "   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.\n",
      "   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.\n",
      "   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.\n",
      "   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.\n",
      "   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.\n",
      "   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.\n",
      "   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.  55. 148.\n",
      " 210. 253. 253. 113.  87. 148.  55.   0.   0.   0.   0.   0.   0.   0.\n",
      "   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.  87. 232. 252.\n",
      " 253. 189. 210. 252. 252. 253. 168.   0.   0.   0.   0.   0.   0.   0.\n",
      "   0.   0.   0.   0.   0.   0.   0.   0.   0.   4.  57. 242. 252. 190.\n",
      "  65.   5.  12. 182. 252. 253. 116.   0.   0.   0.   0.   0.   0.   0.\n",
      "   0.   0.   0.   0.   0.   0.   0.   0.   0.  96. 252. 252. 183.  14.\n",
      "   0.   0.  92. 252. 252. 225.  21.   0.   0.   0.   0.   0.   0.   0.\n",
      "   0.   0.   0.   0.   0.   0.   0.   0. 132. 253. 252. 146.  14.   0.\n",
      "   0.   0. 215. 252. 252.  79.   0.   0.   0.   0.   0.   0.   0.   0.\n",
      "   0.   0.   0.   0.   0.   0.   0. 126. 253. 247. 176.   9.   0.   0.\n",
      "   8.  78. 245. 253. 129.   0.   0.   0.   0.   0.   0.   0.   0.   0.\n",
      "   0.   0.   0.   0.   0.   0.  16. 232. 252. 176.   0.   0.   0.  36.\n",
      " 201. 252. 252. 169.  11.   0.   0.   0.   0.   0.   0.   0.   0.   0.\n",
      "   0.   0.   0.   0.   0.   0.  22. 252. 252.  30.  22. 119. 197. 241.\n",
      " 253. 252. 251.  77.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.\n",
      "   0.   0.   0.   0.   0.   0.  16. 231. 252. 253. 252. 252. 252. 226.\n",
      " 227. 252. 231.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.\n",
      "   0.   0.   0.   0.   0.   0.   0.  55. 235. 253. 217. 138.  42.  24.\n",
      " 192. 252. 143.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.\n",
      "   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.  62.\n",
      " 255. 253. 109.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.\n",
      "   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.  71.\n",
      " 253. 252.  21.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.\n",
      "   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.\n",
      " 253. 252.  21.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.\n",
      "   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.  71.\n",
      " 253. 252.  21.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.\n",
      "   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0. 106.\n",
      " 253. 252.  21.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.\n",
      "   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.  45.\n",
      " 255. 253.  21.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.\n",
      "   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.\n",
      " 218. 252.  56.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.\n",
      "   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.\n",
      "  96. 252. 189.  42.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.\n",
      "   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.\n",
      "  14. 184. 252. 170.  11.   0.   0.   0.   0.   0.   0.   0.   0.   0.\n",
      "   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.\n",
      "   0.  14. 147. 252.  42.   0.   0.   0.   0.   0.   0.   0.   0.   0.\n",
      "   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.\n",
      "   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.]\n",
      "\n",
      "As image:\n",
      "\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "index = 4\n",
    "print(\"Value of datapoint no. {}:\\n{}\\n\".format(index,mnist.data[index]))\n",
    "print(\"As image:\\n\")\n",
    "plt.imshow(mnist.data[index].reshape(28,28),cmap=plt.cm.gray_r)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To make things a little bit simpler (and faster!), we can extract from the data binary subsets, that only contain the data for two selected digits:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The first datapoint now is: \n",
      "\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7        3\n",
      "10       3\n",
      "12       3\n",
      "15       7\n",
      "27       3\n",
      "        ..\n",
      "69975    3\n",
      "69979    7\n",
      "69986    3\n",
      "69990    7\n",
      "69996    3\n",
      "Name: class, Length: 14434, dtype: category\n",
      "Categories (10, object): ['0', '1', '2', '3', ..., '6', '7', '8', '9']\n"
     ]
    }
   ],
   "source": [
    "digit0='3'\n",
    "digit1='7'\n",
    "mnist_bin_data=mnist.data[np.logical_or(mnist.target==digit0,mnist.target==digit1)]\n",
    "mnist_bin_target=mnist.target[np.logical_or(mnist.target==digit0,mnist.target==digit1)]\n",
    "print(\"The first datapoint now is: \\n\")\n",
    "plt.imshow(mnist_bin_data[0].reshape(28,28),cmap=plt.cm.gray_r)\n",
    "plt.show()\n",
    "print(mnist_bin_target)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Exercise 1 [SVM]:** Split the mnist_bin data into training and test set. Learn different SVM models by varying the kernel functions (SVM). For each configuration, determine the time it takes to learn the model, and the accuracy on the test data. \n",
    "\n",
    "You can get the current time using:\n",
    "\n",
    "`import time` <br>\n",
    "`now = time.time()`\n",
    "\n",
    "*Caution*: for some configurations, learning here can take a little while (several minutes).\n",
    "\n",
    "Using the numpy where() function, one can extract the indices of the test cases that were misclassified: <br>\n",
    "`misclass = np.where(test != predictions)` <br>\n",
    "Inspect some misclassified cases. Do they correspond to hard to recognize digits (also for the human reader)? \n",
    "\n",
    "How do results (time and accuracy) change, depending on whether you consider an 'easy' binary task (e.g., distinguishing '1' and '0'), or a more difficult one (e.g., '4' vs. '5'). \n",
    "\n",
    "Identify one or several good configurations that give a reasonable combination of accuracy and runtime. Use these configurations to perform a full classification of the 10 classes in the original dataset (after split into train/test). Using `sklearn.metrics.confusion_matrix` you can get an overview of all combinations of true and predicted labels. What does this tell you about which digits are easy, and which ones are difficult to recognize, and which ones are most easily confused?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Amount of time: 7.720912933349609 for the linear kernel\n",
      "The score for training set: 1.0\n",
      "The score for test set: 0.9795635607897472\n"
     ]
    }
   ],
   "source": [
    "train, test, train_lables, test_Labels = sklearn.model_selection.train_test_split(mnist_bin_data,mnist_bin_target,test_size=0.2)\n",
    "now = time.time()\n",
    "model = SVC(kernel='linear')\n",
    "model.fit(train,train_lables)\n",
    "then = time.time()\n",
    "print(\"Amount of time: \"+str(then-now)+ \" for the linear kernel\")\n",
    "print(\"The score for training set: \"+str(model.score(train,train_lables)))\n",
    "print(\"The score for test set: \"+ str(model.score(test,test_Labels)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Amount of time: 5.066112995147705 for the rbf kernel\n",
      "The score for training set: 0.9980081406425911\n",
      "The score for test set: 0.9948042951160374\n"
     ]
    }
   ],
   "source": [
    "now = time.time()\n",
    "model = SVC(kernel='rbf')\n",
    "model.fit(train,train_lables)\n",
    "then = time.time()\n",
    "print(\"Amount of time: \"+str(then-now)+ \" for the rbf kernel\")\n",
    "print(\"The score for training set: \"+str(model.score(train,train_lables)))\n",
    "print(\"The score for test set: \"+ str(model.score(test,test_Labels)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Amount of time: 5.364880084991455 for the poly kernel\n",
      "The score for training set: 0.9974885251580498\n",
      "The score for test set: 0.9937651541392449\n"
     ]
    }
   ],
   "source": [
    "now = time.time()\n",
    "model = SVC(kernel='poly')\n",
    "model.fit(train,train_lables)\n",
    "then = time.time()\n",
    "print(\"Amount of time: \"+str(then-now)+ \" for the poly kernel\")\n",
    "print(\"The score for training set: \"+str(model.score(train,train_lables)))\n",
    "print(\"The score for test set: \"+ str(model.score(test,test_Labels)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Jeppe\\AppData\\Local\\Temp\\ipykernel_11828\\1689489966.py:2: DeprecationWarning: elementwise comparison failed; this will raise an error in the future.\n",
      "  missclass = np.where(test != predictions)\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "predictions = model.predict(test)\n",
    "missclass = np.where(test != predictions)\n",
    "for i in range(len(missclass)):\n",
    "    plt.imshow(test[missclass[i]].reshape(28,28),cmap=plt.cm.gray_r)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The reason why an classification between  '1' and '0' might be easier than a binary classification between '4' and '5', could be that 1 and 0 does not occupy the same pixels in the image, or does not have the same number of pixels. While 4 and 5 occupy some of the same pixels, and have about the same number of pixels in the image. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train, test, train_lables, test_Labels = sklearn.model_selection.train_test_split(mnist.data,mnist.target,test_size=0.2)\n",
    "# now = time.time()\n",
    "# model = SVC(kernel='linear')\n",
    "# model.fit(train,train_lables)\n",
    "# then = time.time()\n",
    "# print(\"Amount of time: \"+str(then-now)+ \" for the linear kernel\")\n",
    "# print(\"The score for training set: \"+str(model.score(train,train_lables)))\n",
    "# print(\"The score for test set: \"+ str(model.score(test,test_Labels)))\n",
    "# print(sklearn.metrics.confusion_matrix(test_Labels,model.predict(test)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Exercise 2 [SVM]:** Consider how the current data representation \"presents\" the digits to the classifiers, and try to improve this:<br>\n",
    "\n",
    "**a)** Manually design feature functions for which you expect that based on your new features SVM classifiers can achieve a better accuracy than with the original features. Transform the data into your new feature space, and learn new classifiers. What accuracies do you get?\n",
    "\n",
    "**b)** Instead of designing an explicit feature mapping as in **a)**, define a suitable measure of similarity for the digits, and implement that measure as a kernel function. (Optional: verify that the function you have defined actually satisfies the positive-semidefiniteness property.) Use your kernel function as a custom kernel for the SVC classifier.  See http://scikit-learn.org/stable/auto_examples/svm/plot_custom_kernel.html#sphx-glr-auto-examples-svm-plot-custom-kernel-py for an example."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "digit0='0'\n",
    "digit1='1'\n",
    "mnist_bin_data=mnist.data[np.logical_or(mnist.target==digit0,mnist.target==digit1)]\n",
    "mnist_bin_target=mnist.target[np.logical_or(mnist.target==digit0,mnist.target==digit1)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gaussian Kernel\n",
      "Duration elapsed 2.28 seconds\n",
      "Accuracy on training set: 0.94\n",
      "Accuracy on test set: 0.94\n",
      "Confusion matrix: \n",
      "[[1868  190]\n",
      " [  98 2278]]\n"
     ]
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(mnist_bin_data, mnist_bin_target, test_size=.30, random_state=0)\n",
    "X_train_map, X_test_map = np.sum(X_train, axis=1).reshape(-1, 1), np.sum(X_test, axis=1).reshape(-1, 1)\n",
    "X_train_map.shape, X_test_map.shape\n",
    "model = SVC(kernel='poly')\n",
    "now = time.time()\n",
    "model.fit(X_train_map, y_train)\n",
    "end = time.time()\n",
    "print('Gaussian Kernel')\n",
    "print(f'Duration elapsed {(end - now):.2f} seconds')\n",
    "print(f'Accuracy on training set: {model.score(X_train_map, y_train):.2f}')\n",
    "print(f'Accuracy on test set: {model.score(X_test_map, y_test):.2f}')\n",
    "print(f'Confusion matrix: \\n{confusion_matrix(y_test, model.predict(X_test_map))}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gaussian Kernel\n",
      "Duration elapsed 37.22 seconds\n",
      "Accuracy on training set: 0.94\n",
      "Accuracy on test set: 0.94\n",
      "Confusion matrix: \n",
      "[[1907  151]\n",
      " [ 129 2247]]\n"
     ]
    }
   ],
   "source": [
    "def my_kernel(X, Y):\n",
    "    \"\"\"\n",
    "    We create a custom kernel:\n",
    "\n",
    "                 (2  0)\n",
    "    k(X, Y) = X  (    ) Y.T\n",
    "                 (0  1)\n",
    "    \"\"\"\n",
    "    M = np.array([[2, 0], [0, 1.0]])\n",
    "    return np.dot(X, Y.T)\n",
    "\n",
    "model = SVC(kernel=my_kernel)\n",
    "now = time.time()\n",
    "model.fit(X_train_map, y_train)\n",
    "end = time.time()\n",
    "print('Gaussian Kernel')\n",
    "print(f'Duration elapsed {(end - now):.2f} seconds')\n",
    "print(f'Accuracy on training set: {model.score(X_train_map, y_train):.2f}')\n",
    "print(f'Accuracy on test set: {model.score(X_test_map, y_test):.2f}')\n",
    "print(f'Confusion matrix: \\n{confusion_matrix(y_test, model.predict(X_test_map))}')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
